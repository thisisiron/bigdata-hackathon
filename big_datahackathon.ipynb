{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/training_new.csv', header=None, encoding='utf-8', names=[\"date\", \"office\", \"desti\", \"quantity\"])\n",
    "test = pd.read_csv('./data/submit_example.csv', encoding='utf-8', names=[\"date\", \"desti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('./data/training_gi_new.csv', header=None, encoding='utf-8', names=[\"date\", \"desti\", \"quantity\"])\n",
    "test2 = pd.read_csv('./data/submit_example2.csv', encoding='utf-8', names=[\"date\", \"desti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pop = pd.read_csv('./data/seoul_population.txt', encoding='utf-8', sep='\\t',usecols=['지역', '인구', '인구밀도(명/㎢)'])\n",
    "data_pop = data_pop[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['date', 'desti']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date에 따른 컬럼 변환과 추가\n",
    "'month', 'day', 'day_of_week', 'season'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data[\"date\"], format='%Y%m%d',)\n",
    "test['date'] = pd.to_datetime(test[\"date\"], format='%Y-%m-%d',)\n",
    "data2['date'] = pd.to_datetime(data2[\"date\"], format='%Y%m%d',)\n",
    "test2['date'] = pd.to_datetime(test2[\"date\"], format='%Y-%m-%d',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data 요일 컬럼 추가\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "data['day_of_week'] = pd.to_datetime(data[\"date\"], format='%Y%m%d',).dt.weekday_name\n",
    "\n",
    "data2['month'] = data2['date'].dt.month\n",
    "data2['day'] = data2['date'].dt.day\n",
    "data2['day_of_week'] = pd.to_datetime(data2[\"date\"], format='%Y%m%d',).dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data 요일 컬럼 추가\n",
    "test['month'] = test['date'].dt.month\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = pd.to_datetime(test[\"date\"], format='%Y-%m-%d',).dt.weekday_name\n",
    "\n",
    "test2['month'] = test2['date'].dt.month\n",
    "test2['day'] = test2['date'].dt.day\n",
    "test2['day_of_week'] = pd.to_datetime(test2[\"date\"], format='%Y-%m-%d',).dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(row):\n",
    "    '''\n",
    "    month에 따른 계절 추가\n",
    "    '''\n",
    "    if row['month'] >= 3 and row['month'] <= 5:\n",
    "        return 'spring'\n",
    "    elif row['month'] >= 6 and row['month'] <= 8:\n",
    "        return 'summer'\n",
    "    elif row['month'] >= 9 and row['month'] <= 11:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['season'] = data.apply(get_season, axis=1)\n",
    "test['season'] = test.apply(get_season, axis=1)\n",
    "data2['season'] = data2.apply(get_season, axis=1)\n",
    "test2['season'] = test2.apply(get_season, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공휴일, 공휴일 다음날 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_holiday(row):\n",
    "    '''\n",
    "    공휴일이면 1, 공휴일 아니면 0으로 설정\n",
    "    '''\n",
    "    if row['day_of_week'] == 'Saturday' or row['day_of_week'] == 'Sunday':\n",
    "        return \"holiday\"\n",
    "    elif (row['date'].month == 1 and row['date'].day == 1) or (row['date'].month == 2 and row['date'].day >= 15 and row['date'].day <= 18) or \\\n",
    "    (row['date'].month == 3 and row['date'].day == 1) or (row['date'].month == 5 and row['date'].day >= 5 and row['date'].day <= 7) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 22) or (row['date'].month == 6 and row['date'].day == 6) or (row['date'].month == 6 and row['date'].day == 13) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 15) or (row['date'].month == 9 and row['date'].day >= 22 and row['date'].day <= 26) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 3) or (row['date'].month == 10 and row['date'].day == 9) or (row['date'].month == 12 and row['date'].day == 25):\n",
    "        return \"holiday\"\n",
    "    else:\n",
    "        return \"noholiday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holiday'] = data.apply(set_holiday, axis=1)\n",
    "test['holiday'] = test.apply(set_holiday, axis=1)\n",
    "data2['holiday'] = data2.apply(set_holiday, axis=1)\n",
    "test2['holiday'] = test2.apply(set_holiday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nextday(row):\n",
    "    '''\n",
    "    공휴일 다음날이면 1, 공휴일 다음날이 아니면 0으로 설정\n",
    "    '''\n",
    "    if row['day_of_week'] == 'Saturday' or row['day_of_week'] == 'Sunday':\n",
    "        return \"nonextday\"\n",
    "    elif (row['date'].month == 1 and row['date'].day == 1) or (row['date'].month == 2 and row['date'].day >= 15 and row['date'].day <= 18) or \\\n",
    "    (row['date'].month == 3 and row['date'].day == 1) or (row['date'].month == 5 and row['date'].day >= 5 and row['date'].day <= 7) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 22) or (row['date'].month == 6 and row['date'].day == 6) or (row['date'].month == 6 and row['date'].day == 13) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 15) or (row['date'].month == 9 and row['date'].day >= 22 and row['date'].day <= 26) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 3) or (row['date'].month == 10 and row['date'].day == 9) or (row['date'].month == 12 and row['date'].day == 25):\n",
    "        return \"nonextday\"\n",
    "    elif row['day_of_week'] == 'Monday':\n",
    "        return 'nextday'\n",
    "    elif (row['date'].month == 1 and row['date'].day == 2) or (row['date'].month == 2 and row['date'].day >= 5 and row['date'].day <= 9) or \\\n",
    "    (row['date'].month == 2 and row['date'].day == 19) or (row['date'].month == 5 and row['date'].day == 8) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 23) or (row['date'].month == 6 and row['date'].day == 7) or (row['date'].month == 6 and row['date'].day == 14) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 16) or (row['date'].month == 9 and row['date'].day == 27) or (row['date'].month == 9 and row['date'].day >= 10 and row['date'].day <= 14) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 4) or (row['date'].month == 10 and row['date'].day == 10) or (row['date'].month == 12 and row['date'].day == 26):\n",
    "        return 'nextday'\n",
    "    else:\n",
    "        return 'nonextday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nextday'] = data.apply(set_nextday, axis=1)\n",
    "test['nextday'] = test.apply(set_nextday, axis=1)\n",
    "data2['nextday'] = data2.apply(set_nextday, axis=1)\n",
    "test2['nextday'] = test2.apply(set_nextday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pop_join = data.join(data_pop.set_index('desti'), on='desti')\n",
    "\n",
    "# data_pop_join['population'] = data_pop_join.population.astype(int)\n",
    "# data_pop_join\n",
    "\n",
    "# def set_ratio(row):\n",
    "#     return row['quantity'] / row['population']\n",
    "\n",
    "# data_pop_join['ratio'] = data_pop_join.apply(set_ratio, axis=1)\n",
    "# data_pop_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desti</th>\n",
       "      <th>quantity</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>nextday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5829</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>7455</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>10086</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5929</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>14913</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  desti  quantity  month  day day_of_week  season    holiday  \\\n",
       "0 2017-12-01      0      5829     12    1      Friday  winter  noholiday   \n",
       "1 2017-12-01      1      7455     12    1      Friday  winter  noholiday   \n",
       "2 2017-12-01      2     10086     12    1      Friday  winter  noholiday   \n",
       "3 2017-12-01      3      5929     12    1      Friday  winter  noholiday   \n",
       "4 2017-12-01      4     14913     12    1      Friday  winter  noholiday   \n",
       "\n",
       "     nextday  \n",
       "0  nonextday  \n",
       "1  nonextday  \n",
       "2  nonextday  \n",
       "3  nonextday  \n",
       "4  nonextday  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data.drop([\"quantity\", \"date\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.drop([\"quantity\", \"date\"], axis=1) # 훈련 세트를 위해 레이블 삭제\n",
    "train_data_labels = data[\"quantity\"].copy()\n",
    "train_data_cat = train_data[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "train_data_num = train_data.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.drop([\"date\"], axis=1)\n",
    "test_data_cat = test_data[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "test_data_num = test_data.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = data2.drop([\"quantity\", \"date\"], axis=1) # 훈련 세트를 위해 레이블 삭제\n",
    "train_data_labels_2 = data2[\"quantity\"].copy()\n",
    "\n",
    "train_data_cat_2 = train_data_2[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "train_data_num_2 = train_data_2.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = test2.drop([\"date\"], axis=1)\n",
    "test_data_cat_2 = test_data_2[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "test_data_num_2 = test_data_2.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desti</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>nextday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desti  month  day day_of_week  season  holiday    nextday\n",
       "0     21     12   24      Sunday  winter  holiday  nonextday\n",
       "1     16     12   24      Sunday  winter  holiday  nonextday\n",
       "2     20     12   24      Sunday  winter  holiday  nonextday\n",
       "3      8     12   24      Sunday  winter  holiday  nonextday\n",
       "4     19     12   24      Sunday  winter  holiday  nonextday"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desti</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>nextday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desti  month  day day_of_week season    holiday  nextday\n",
       "0      0      9   11     Tuesday   fall  noholiday  nextday\n",
       "1      1      9   11     Tuesday   fall  noholiday  nextday\n",
       "2      2      9   11     Tuesday   fall  noholiday  nextday\n",
       "3      3      9   11     Tuesday   fall  noholiday  nextday\n",
       "4      4      9   11     Tuesday   fall  noholiday  nextday"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding과 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(2))\n",
    "#         ('minmax_scaler', MinMaxScaler()),\n",
    "    ])\n",
    "\n",
    "\n",
    "num_attribs = list(train_data_num)\n",
    "cat_attribs = ['day_of_week', 'season', 'holiday', 'nextday']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared = full_pipeline.fit_transform(train_data)\n",
    "train_data_prepared_2 = full_pipeline.fit_transform(train_data_2)\n",
    "\n",
    "test_data_prepared = full_pipeline.transform(test_data)\n",
    "test_data_prepared_2 = full_pipeline.transform(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -1.66387623,  1.63216768, -1.6580551 ,  2.76848412,\n",
       "       -2.71572501,  2.75879848,  2.66397134, -2.70622395,  2.74914672,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_prepared[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [7179.00886244 7220.37462591 7261.74038938 7303.10615285 7344.47191632]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플 몇 개를 사용해 전체 파이프라인을 적용\n",
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", lin_reg.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤포레스트 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=150, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.fit(train_data_prepared_2, train_data_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest_reg.predict(test_data_prepared_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest_reg.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [ 5910.1  7595.  10086.   6039.1 15518.7]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플 몇 개를 사용해 테스트하기\n",
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", forest_reg.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 최적화 하이퍼 파라미터 서치\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "min_samples_leaf = [1, 2, 4, 10, 50]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 62.3min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 104.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10, 20], 'min_samples_leaf': [1, 2, 4, 10, 50], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_random.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_random.fit(train_data_prepared_2, train_data_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rf_random.best_estimator_.predict(test_data_prepared_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.around(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means, Random Forest 통합 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union  = Pipeline([\n",
    "    ('k_means_5', KMeans(n_clusters=5)),\n",
    "    ('random_forest', RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [  597.7   336.9   338.9   145.4   355.4   188.3   289.    357.1   337.9\n",
      "   337.4   246.1   201.7   172.    271.    177.6   295.6   238.6   358.6\n",
      "   211.6   771.6   401.8   313.3  1589.9   398.1   621.2   359.4   182.6\n",
      "   812.8   307.4   247.5   315.3   290.8   234.5   344.    546.3   233.1\n",
      "   355.7   312.5   156.    267.3   664.7   340.    236.9   298.1   445.8\n",
      "   218.6   324.9   368.7  1832.5   298.4 13247.6 20997.5  9298.2  5478.8\n",
      "  7822.7  9869.6 13939.3 11506.4 15194.5  9589.7 10246.3 14399.7 19987.3\n",
      " 13426.4 10164.1  7965.5  8045.4  8021.5  6112.7 10614.2  8888.7 11295.1\n",
      "  9611.5 10559.8 11318.8  4995.2  4985.5  6936.7  3332.3 12683.7  8814.9\n",
      "  5987.7  5921.4  3099.1  5290.8  5008.3  4432.3  5710.  13874.6  6599.8\n",
      "  6111.   6187.3  5836.   8668.1  7166.1  8873.2  8469.2  6864.7  8328.9\n",
      "  6979.2   214.2   269.9   457.4   408.2   304.4   386.1   461.4   448.2\n",
      "   605.1   239.8   429.3   450.6   466.6   452.1   330.9   302.4   607.4\n",
      "  2094.3   715.3   391.4   748.5   346.8   268.3   965.3   482.2 17436.8\n",
      " 12944.9  9979.8 10101.2  8468.6 13786.3  5875.2  9370.6  8191.4  8932.9\n",
      " 10776.7 13245.  10779.1  7173.2  7580.5 12978.3 19240.8  5261.8  9752.8\n",
      " 11207.5  7238.9  9156.3  9653.6 14090.1  9679.4 13001.4  9441.9  7961.1\n",
      " 13038.6 14993.8 11662.3 20523.4 10683.5 10441.9  9216.2  7561.1 11316.6\n",
      "  7896.9  6024.9 10160.6  7331.1  8042.1  9274.5  9227.1  5299.3  7349.4\n",
      " 10364.   6798.8  6463.1  4999.6  3487.8  2299.9  2037.2  1229.1   694.3\n",
      "  2352.4  2659.6  2462.5  1831.   2233.6  3199.    657.7  1921.1   722.4\n",
      "  2279.2  2156.6  1453.5  1310.9  1492.7  2053.8   950.8  1578.1  2156.1\n",
      "  1876.1  2118.2   215.7   571.4   258.1   384.8   474.5  1713.2   311.4\n",
      "   313.2   293.8   500.7   196.2   565.1   369.    336.1   301.2   245.4\n",
      "   653.    321.8   537.    278.8   280.5   212.9   184.6   195.3   311.8\n",
      "   301.1   559.9   303.6   285.6   545.4   475.1   306.8   216.6   277.\n",
      "  1720.7   534.7   592.6   467.3   359.4   191.8   371.8   325.6   166.\n",
      "   312.5   316.9   224.3   211.9   261.1   311.6   188.1  8506.8  6058.4\n",
      " 13731.8 15717.1 14026.2 25529.7 11636.9 19761.9 14074.6 16741.8 10325.8\n",
      " 20207.2 13991.8 10589.3 10174.8 14260.4 12310.9 13448.8 14437.2  7743.4\n",
      "  9957.6 12881.2 10098.8 19282.  13643.2  4248.9 11301.8  8761.7  9971.3\n",
      "  7600.3 15940.6  7616.7  7401.4 16429.1  7173.7  7956.1 10696.1  9046.2\n",
      " 11191.5  5690.3  6072.   6201.9  8486.1  8319.6 10334.   7743.5  4573.2\n",
      " 11047.7  6894.1  7108.9   212.1   212.9   307.1   361.5   288.5   439.8\n",
      "   333.3   337.2   555.2   278.4   163.4  2348.8   257.1   343.9   281.3\n",
      "   626.    173.2   205.8   293.6   344.6   465.3   796.6   407.4   230.\n",
      "   361.5  9781.9  6164.  12887.5 16508.3 11266.4  8529.1 23419.9 14825.6\n",
      " 12567.9 16101.5 10760.3  9669.   8659.1  8383.7 10819.6 15272.2 11632.7\n",
      " 11511.8 12100.1  9847.7 11055.3  6347.1 10066.9 23607.8 14587.3  8813.9\n",
      " 16529.5 11859.5  6612.4 13168.9 13901.6 11864.2 11771.4 10301.2  6746.\n",
      "  8903.2  9257.4 10230.1 11489.4 15113.  24271.5 16166.9 17774.3 10468.8\n",
      " 10312.3 15891.9 13304.4 12514.  23921.  15644.2   238.6   624.7   202.9\n",
      "   340.    280.5   844.2   197.1   270.5   353.9   356.1   311.1   404.8\n",
      "   310.1   456.5   223.1  2227.4   552.    303.3   171.2   399.5   332.4\n",
      "   296.2   329.3   386.6   171.7 10131.9  8858.7  9878.2 15247.6  8665.4\n",
      " 22523.6 23972.6 16350.4  6478.8 10937.  11933.  10302.2 16377.7 12068.7\n",
      " 14847.6 10301.1 11588.7 10885.6  6261.2 13923.1 11569.6  9771.1 12596.3\n",
      " 14538.   8518.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측:\", forest_reg.predict(test_data_prepared))\n",
    "result = forest_reg.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR()\n",
    "clf.fit(train_data_prepared, train_data_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [6281.52328698 6287.43266756 6293.26016267 6298.97446499 6304.54378194]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", clf.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sgd.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor()\n",
    "# neigh.fit(train_data_prepared, train_data_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import GridSearchCV\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(neigh, param_grid, cv=10, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [ 5829.  7455. 10086.  5929. 14913.]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", grid.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2189650.640516039"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.around(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_int = result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3894, 11357,  7776, ...,    15,    13,     0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서울지역 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/submit_example.csv', encoding='utf-8', names=[\"date\", \"desti\"])\n",
    "result_pd = pd.DataFrame(result_int)\n",
    "submit_csv = pd.concat([submit, result_pd], axis=1)\n",
    "submit_csv.to_csv('submit.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경인지역 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2 = pd.read_csv('./data/submit_example2.csv', encoding='utf-8', names=[\"date\", \"desti\"])\n",
    "result_pd = pd.DataFrame(result_int)\n",
    "submit_csv_2 = pd.concat([submit_2, result_pd], axis=1)\n",
    "submit_csv_2.to_csv('submit_2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For deep learning model \n",
    "import keras\n",
    "from keras.layers import Dense, Input, concatenate, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5829,  7455, 10086, ..., 16106, 11191,  5884], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_prepared\n",
    "Y = train_data_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6883 samples, validate on 1721 samples\n",
      "Epoch 1/100\n",
      "6883/6883 [==============================] - 5s 782us/step - loss: 24019806.9369 - acc: 1.4529e-04 - val_loss: 15990906.0802 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6883/6883 [==============================] - 5s 764us/step - loss: 6298805.1723 - acc: 7.2643e-04 - val_loss: 15765093.7501 - val_acc: 5.8106e-04\n",
      "Epoch 3/100\n",
      "6883/6883 [==============================] - 5s 699us/step - loss: 6251347.2159 - acc: 4.3586e-04 - val_loss: 15600993.8791 - val_acc: 0.0012\n",
      "Epoch 4/100\n",
      "6883/6883 [==============================] - 6s 801us/step - loss: 6195917.1405 - acc: 5.8114e-04 - val_loss: 15758208.9367 - val_acc: 0.0017\n",
      "Epoch 5/100\n",
      "6883/6883 [==============================] - 6s 808us/step - loss: 6160372.7108 - acc: 8.7171e-04 - val_loss: 16865049.9187 - val_acc: 5.8106e-04\n",
      "Epoch 6/100\n",
      "6883/6883 [==============================] - 6s 821us/step - loss: 6040295.2510 - acc: 7.2643e-04 - val_loss: 15573848.6357 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6883/6883 [==============================] - 5s 727us/step - loss: 5943928.5960 - acc: 0.0010 - val_loss: 15167778.4567 - val_acc: 5.8106e-04\n",
      "Epoch 8/100\n",
      "6883/6883 [==============================] - 5s 670us/step - loss: 5939147.7920 - acc: 5.8114e-04 - val_loss: 16682843.9268 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5945700.5487 - acc: 2.9057e-04 - val_loss: 14636323.5921 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5905947.5020 - acc: 1.4529e-04 - val_loss: 13896459.8466 - val_acc: 5.8106e-04\n",
      "Epoch 11/100\n",
      "6883/6883 [==============================] - 5s 678us/step - loss: 5847400.2463 - acc: 0.0000e+00 - val_loss: 14068904.1290 - val_acc: 5.8106e-04\n",
      "Epoch 12/100\n",
      "6883/6883 [==============================] - 6s 841us/step - loss: 5811174.6779 - acc: 7.2643e-04 - val_loss: 15244086.2324 - val_acc: 5.8106e-04\n",
      "Epoch 13/100\n",
      "6883/6883 [==============================] - 5s 738us/step - loss: 5795962.3748 - acc: 4.3586e-04 - val_loss: 14654568.7542 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6883/6883 [==============================] - 5s 727us/step - loss: 5760606.8887 - acc: 2.9057e-04 - val_loss: 13850974.5131 - val_acc: 5.8106e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/100\n",
      "6883/6883 [==============================] - 5s 791us/step - loss: 5621148.1685 - acc: 5.8114e-04 - val_loss: 14369183.4492 - val_acc: 5.8106e-04\n",
      "Epoch 16/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 5579183.3397 - acc: 0.0012 - val_loss: 15293432.8449 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 5667122.9441 - acc: 0.0013 - val_loss: 14227727.9814 - val_acc: 5.8106e-04\n",
      "Epoch 18/100\n",
      "6883/6883 [==============================] - 6s 873us/step - loss: 5685772.6449 - acc: 0.0012 - val_loss: 13626366.6630 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "6883/6883 [==============================] - 5s 732us/step - loss: 5571248.0236 - acc: 8.7171e-04 - val_loss: 13345354.6496 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "6883/6883 [==============================] - 5s 654us/step - loss: 5562476.2492 - acc: 0.0012 - val_loss: 13829882.5450 - val_acc: 5.8106e-04\n",
      "Epoch 21/100\n",
      "6883/6883 [==============================] - 5s 662us/step - loss: 5579529.8404 - acc: 4.3586e-04 - val_loss: 13869256.0209 - val_acc: 0.0012\n",
      "Epoch 22/100\n",
      "6883/6883 [==============================] - 6s 883us/step - loss: 5568244.7356 - acc: 7.2643e-04 - val_loss: 13276337.5811 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5606410.7729 - acc: 4.3586e-04 - val_loss: 13716067.3225 - val_acc: 0.0012\n",
      "Epoch 24/100\n",
      "6883/6883 [==============================] - 5s 720us/step - loss: 5557764.0892 - acc: 7.2643e-04 - val_loss: 14189512.7862 - val_acc: 0.0023\n",
      "Epoch 25/100\n",
      "6883/6883 [==============================] - 5s 777us/step - loss: 5538916.5460 - acc: 8.7171e-04 - val_loss: 14962774.7403 - val_acc: 5.8106e-04\n",
      "Epoch 26/100\n",
      "6883/6883 [==============================] - 4s 644us/step - loss: 5495006.7144 - acc: 0.0016 - val_loss: 14522017.6595 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "6883/6883 [==============================] - 5s 778us/step - loss: 5515965.8765 - acc: 0.0012 - val_loss: 13828898.3295 - val_acc: 0.0012\n",
      "Epoch 28/100\n",
      "6883/6883 [==============================] - 6s 887us/step - loss: 5404347.8080 - acc: 5.8114e-04 - val_loss: 12903234.0151 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "6883/6883 [==============================] - 6s 850us/step - loss: 5405666.4975 - acc: 7.2643e-04 - val_loss: 13211277.6212 - val_acc: 0.0012\n",
      "Epoch 30/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 5390765.5283 - acc: 5.8114e-04 - val_loss: 13982347.6310 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "6883/6883 [==============================] - 5s 783us/step - loss: 5389808.3772 - acc: 5.8114e-04 - val_loss: 13446817.1040 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "6883/6883 [==============================] - 5s 792us/step - loss: 5347761.2576 - acc: 0.0012 - val_loss: 14613208.6851 - val_acc: 5.8106e-04\n",
      "Epoch 33/100\n",
      "6883/6883 [==============================] - 5s 733us/step - loss: 5368655.0023 - acc: 7.2643e-04 - val_loss: 14565507.5752 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "6883/6883 [==============================] - 5s 714us/step - loss: 5386407.9248 - acc: 5.8114e-04 - val_loss: 14366548.1697 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/100\n",
      "6883/6883 [==============================] - 6s 935us/step - loss: 5292213.0584 - acc: 4.3586e-04 - val_loss: 13773750.6351 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "6883/6883 [==============================] - 5s 715us/step - loss: 5309293.5115 - acc: 8.7171e-04 - val_loss: 13800923.0105 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "6883/6883 [==============================] - 5s 739us/step - loss: 5196658.7908 - acc: 7.2643e-04 - val_loss: 13735348.3283 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "6883/6883 [==============================] - 5s 680us/step - loss: 5248661.8132 - acc: 0.0013 - val_loss: 14097858.2795 - val_acc: 5.8106e-04\n",
      "Epoch 39/100\n",
      "6883/6883 [==============================] - 5s 733us/step - loss: 5170393.5544 - acc: 8.7171e-04 - val_loss: 13527830.5044 - val_acc: 0.0012\n",
      "Epoch 40/100\n",
      "6883/6883 [==============================] - 5s 670us/step - loss: 5155401.6519 - acc: 0.0015 - val_loss: 13404002.1888 - val_acc: 0.0012\n",
      "Epoch 41/100\n",
      "6883/6883 [==============================] - 5s 672us/step - loss: 5201360.4335 - acc: 8.7171e-04 - val_loss: 13209872.4248 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "6883/6883 [==============================] - 5s 713us/step - loss: 5139656.8556 - acc: 5.8114e-04 - val_loss: 13343570.3382 - val_acc: 0.0012\n",
      "Epoch 43/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5120288.5767 - acc: 8.7171e-04 - val_loss: 13369424.9861 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "6883/6883 [==============================] - 5s 669us/step - loss: 5165525.4498 - acc: 8.7171e-04 - val_loss: 13652060.5445 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 5171312.4841 - acc: 2.9057e-04 - val_loss: 13565098.1220 - val_acc: 5.8106e-04\n",
      "Epoch 46/100\n",
      "6883/6883 [==============================] - 5s 672us/step - loss: 5121748.8350 - acc: 7.2643e-04 - val_loss: 13712346.4248 - val_acc: 5.8106e-04\n",
      "Epoch 47/100\n",
      "6883/6883 [==============================] - 5s 664us/step - loss: 5122999.8482 - acc: 2.9057e-04 - val_loss: 13248028.6467 - val_acc: 0.0012\n",
      "Epoch 48/100\n",
      "6883/6883 [==============================] - 5s 671us/step - loss: 5129981.3772 - acc: 2.9057e-04 - val_loss: 13498506.2719 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 5128698.7664 - acc: 5.8114e-04 - val_loss: 13374864.5863 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 5166929.0145 - acc: 7.2643e-04 - val_loss: 13547611.3661 - val_acc: 0.0012\n",
      "Epoch 51/100\n",
      "6883/6883 [==============================] - 5s 677us/step - loss: 5081680.0230 - acc: 5.8114e-04 - val_loss: 13868442.3730 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "6883/6883 [==============================] - 5s 677us/step - loss: 5093951.7938 - acc: 2.9057e-04 - val_loss: 13059316.0378 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "6883/6883 [==============================] - 5s 699us/step - loss: 5064138.1944 - acc: 0.0013 - val_loss: 13501176.0674 - val_acc: 5.8106e-04\n",
      "Epoch 54/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 5180120.4961 - acc: 4.3586e-04 - val_loss: 13698856.4399 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 55/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5058769.5119 - acc: 0.0016 - val_loss: 13444566.1302 - val_acc: 5.8106e-04\n",
      "Epoch 56/100\n",
      "6883/6883 [==============================] - 5s 691us/step - loss: 5101156.0253 - acc: 5.8114e-04 - val_loss: 13783711.8414 - val_acc: 0.0012\n",
      "Epoch 57/100\n",
      "6883/6883 [==============================] - 5s 721us/step - loss: 5059946.9300 - acc: 4.3586e-04 - val_loss: 13413629.4021 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "6883/6883 [==============================] - 5s 665us/step - loss: 5051410.2387 - acc: 8.7171e-04 - val_loss: 13394703.1075 - val_acc: 0.0012\n",
      "Epoch 59/100\n",
      "6883/6883 [==============================] - 5s 687us/step - loss: 5072371.0222 - acc: 8.7171e-04 - val_loss: 13359180.6920 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "6883/6883 [==============================] - 5s 678us/step - loss: 5018443.3853 - acc: 7.2643e-04 - val_loss: 13524953.6967 - val_acc: 5.8106e-04\n",
      "Epoch 61/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 4969843.6682 - acc: 5.8114e-04 - val_loss: 13501740.4550 - val_acc: 5.8106e-04\n",
      "Epoch 62/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 4983171.3291 - acc: 8.7171e-04 - val_loss: 13383423.1203 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "6883/6883 [==============================] - 5s 659us/step - loss: 4977258.2212 - acc: 8.7171e-04 - val_loss: 13139032.4730 - val_acc: 5.8106e-04\n",
      "Epoch 64/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 4982331.3968 - acc: 5.8114e-04 - val_loss: 13504124.0209 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 5034110.7996 - acc: 5.8114e-04 - val_loss: 13426658.7147 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 5037275.3762 - acc: 8.7171e-04 - val_loss: 13553244.6630 - val_acc: 0.0012\n",
      "Epoch 67/100\n",
      "6883/6883 [==============================] - 4s 652us/step - loss: 5016273.1809 - acc: 7.2643e-04 - val_loss: 13429034.4788 - val_acc: 5.8106e-04\n",
      "Epoch 68/100\n",
      "6883/6883 [==============================] - 5s 655us/step - loss: 5030558.1437 - acc: 4.3586e-04 - val_loss: 13561632.5462 - val_acc: 0.0012\n",
      "Epoch 69/100\n",
      "6883/6883 [==============================] - 4s 648us/step - loss: 5022771.6062 - acc: 7.2643e-04 - val_loss: 13460405.6758 - val_acc: 0.0012\n",
      "Epoch 70/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 4997948.0024 - acc: 8.7171e-04 - val_loss: 13387042.8239 - val_acc: 5.8106e-04\n",
      "Epoch 71/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 5002514.0522 - acc: 8.7171e-04 - val_loss: 13437422.7362 - val_acc: 0.0012\n",
      "Epoch 72/100\n",
      "6883/6883 [==============================] - 5s 654us/step - loss: 5027051.8759 - acc: 0.0017 - val_loss: 13413638.2243 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "6883/6883 [==============================] - 5s 660us/step - loss: 4999133.6399 - acc: 1.4529e-04 - val_loss: 13386886.3213 - val_acc: 5.8106e-04\n",
      "Epoch 74/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 5034712.0774 - acc: 0.0013 - val_loss: 13378870.3051 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 75/100\n",
      "6883/6883 [==============================] - 5s 676us/step - loss: 4974733.3351 - acc: 8.7171e-04 - val_loss: 13446774.5625 - val_acc: 5.8106e-04\n",
      "Epoch 76/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 4955611.3300 - acc: 4.3586e-04 - val_loss: 13398580.3719 - val_acc: 0.0012\n",
      "Epoch 77/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5022593.7733 - acc: 2.9057e-04 - val_loss: 13459559.4718 - val_acc: 0.0012\n",
      "Epoch 78/100\n",
      "6883/6883 [==============================] - 5s 676us/step - loss: 4983919.4796 - acc: 5.8114e-04 - val_loss: 13439210.5270 - val_acc: 0.0012\n",
      "Epoch 79/100\n",
      "6883/6883 [==============================] - 5s 664us/step - loss: 4910187.8425 - acc: 7.2643e-04 - val_loss: 13399135.5212 - val_acc: 5.8106e-04\n",
      "Epoch 80/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 4974858.7426 - acc: 2.9057e-04 - val_loss: 13449256.5206 - val_acc: 5.8106e-04\n",
      "Epoch 81/100\n",
      "6883/6883 [==============================] - 5s 662us/step - loss: 4961609.8817 - acc: 7.2643e-04 - val_loss: 13467521.3963 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 4975563.6873 - acc: 8.7171e-04 - val_loss: 13409012.1859 - val_acc: 0.0012\n",
      "Epoch 83/100\n",
      "6883/6883 [==============================] - 5s 695us/step - loss: 4951099.0151 - acc: 0.0012 - val_loss: 13439802.8919 - val_acc: 5.8106e-04\n",
      "Epoch 84/100\n",
      "6883/6883 [==============================] - 6s 882us/step - loss: 4941026.2481 - acc: 7.2643e-04 - val_loss: 13421417.5805 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 85/100\n",
      "6883/6883 [==============================] - 6s 914us/step - loss: 4997101.6114 - acc: 7.2643e-04 - val_loss: 13431274.3498 - val_acc: 0.0012\n",
      "Epoch 86/100\n",
      "6883/6883 [==============================] - 5s 748us/step - loss: 5041673.6389 - acc: 5.8114e-04 - val_loss: 13416292.0261 - val_acc: 5.8106e-04\n",
      "Epoch 87/100\n",
      "6883/6883 [==============================] - 7s 973us/step - loss: 4956891.5886 - acc: 4.3586e-04 - val_loss: 13418018.6089 - val_acc: 5.8106e-04\n",
      "Epoch 88/100\n",
      "6883/6883 [==============================] - 6s 913us/step - loss: 4979234.0434 - acc: 4.3586e-04 - val_loss: 13414014.1726 - val_acc: 5.8106e-04\n",
      "Epoch 89/100\n",
      "6883/6883 [==============================] - 7s 1ms/step - loss: 4958917.1951 - acc: 0.0010 - val_loss: 13427352.2202 - val_acc: 5.8106e-04\n",
      "Epoch 90/100\n",
      "6883/6883 [==============================] - 6s 822us/step - loss: 4985241.5978 - acc: 4.3586e-04 - val_loss: 13424677.2661 - val_acc: 0.0012\n",
      "Epoch 91/100\n",
      "6883/6883 [==============================] - 5s 682us/step - loss: 5010232.6526 - acc: 0.0013 - val_loss: 13402227.4126 - val_acc: 5.8106e-04\n",
      "Epoch 92/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5009976.4831 - acc: 0.0010 - val_loss: 13409398.7013 - val_acc: 0.0017\n",
      "Epoch 93/100\n",
      "6883/6883 [==============================] - 5s 714us/step - loss: 5007828.2416 - acc: 0.0015 - val_loss: 13387353.9268 - val_acc: 0.0012\n",
      "Epoch 94/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 4991460.9127 - acc: 5.8114e-04 - val_loss: 13386499.4033 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 95/100\n",
      "6883/6883 [==============================] - 5s 661us/step - loss: 5018218.9831 - acc: 2.9057e-04 - val_loss: 13392491.0732 - val_acc: 0.0012\n",
      "Epoch 96/100\n",
      "6883/6883 [==============================] - 5s 681us/step - loss: 4983028.4490 - acc: 7.2643e-04 - val_loss: 13393797.5828 - val_acc: 0.0012\n",
      "Epoch 97/100\n",
      "6883/6883 [==============================] - 5s 763us/step - loss: 4959255.4094 - acc: 4.3586e-04 - val_loss: 13396459.8135 - val_acc: 0.0012\n",
      "Epoch 98/100\n",
      "6883/6883 [==============================] - 5s 755us/step - loss: 4989062.6642 - acc: 7.2643e-04 - val_loss: 13391451.2719 - val_acc: 0.0012\n",
      "Epoch 99/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 5006413.5400 - acc: 0.0012 - val_loss: 13392577.1354 - val_acc: 0.0012\n",
      "Epoch 100/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 4927212.1027 - acc: 8.7171e-04 - val_loss: 13403480.7037 - val_acc: 0.0012\n"
     ]
    }
   ],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense((1024), activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense((512), activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense((256), activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(1, name='num_output')(x)\n",
    "\n",
    "model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=10, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "#     EarlyStopping('val_loss', patience=15)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "]\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, batch_size=64, callbacks=callbacks, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
