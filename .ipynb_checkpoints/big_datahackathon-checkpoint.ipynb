{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/training_new.csv', header=None, encoding='utf-8', names=[\"date\", \"office\", \"desti\", \"quantity\"])\n",
    "data_pop = pd.read_csv('./data/seoul_population.txt', encoding='utf-8', sep='\\t',usecols=['지역', '인구', '인구밀도(명/㎢)'])\n",
    "test = pd.read_csv('./data/submit_example.csv', encoding='utf-8', names=[\"date\", \"desti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pop = data_pop[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['date', 'desti']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date에 따른 컬럼 변환과 추가\n",
    "'month', 'day', 'day_of_week', 'season'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data[\"date\"], format='%Y%m%d',)\n",
    "test['date'] = pd.to_datetime(test[\"date\"], format='%Y-%m-%d',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 컬럼 추가\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "data['day_of_week'] = pd.to_datetime(data[\"date\"], format='%Y%m%d',).dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 컬럼 추가\n",
    "test['month'] = test['date'].dt.month\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = pd.to_datetime(test[\"date\"], format='%Y-%m-%d',).dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(row):\n",
    "    '''\n",
    "    month에 따른 계절 추가\n",
    "    '''\n",
    "    if row['month'] >= 3 and row['month'] <= 5:\n",
    "        return 'spring'\n",
    "    elif row['month'] >= 6 and row['month'] <= 8:\n",
    "        return 'summer'\n",
    "    elif row['month'] >= 9 and row['month'] <= 11:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['season'] = data.apply(get_season, axis=1)\n",
    "test['season'] = test.apply(get_season, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공휴일, 공휴일 다음날 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_holiday(row):\n",
    "    '''\n",
    "    공휴일이면 1, 공휴일 아니면 0으로 설정\n",
    "    '''\n",
    "    if row['day_of_week'] == 'Saturday' or row['day_of_week'] == 'Sunday':\n",
    "        return \"holiday\"\n",
    "    elif (row['date'].month == 1 and row['date'].day == 1) or (row['date'].month == 2 and row['date'].day >= 15 and row['date'].day <= 18) or \\\n",
    "    (row['date'].month == 3 and row['date'].day == 1) or (row['date'].month == 5 and row['date'].day >= 5 and row['date'].day <= 7) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 22) or (row['date'].month == 6 and row['date'].day == 6) or (row['date'].month == 6 and row['date'].day == 13) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 15) or (row['date'].month == 9 and row['date'].day >= 22 and row['date'].day <= 26) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 3) or (row['date'].month == 10 and row['date'].day == 9) or (row['date'].month == 12 and row['date'].day == 25):\n",
    "        return \"holiday\"\n",
    "    else:\n",
    "        return \"noholiday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holiday'] = data.apply(set_holiday, axis=1)\n",
    "test['holiday'] = test.apply(set_holiday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nextday(row):\n",
    "    '''\n",
    "    공휴일 다음날이면 1, 공휴일 다음날이 아니면 0으로 설정\n",
    "    '''\n",
    "    if row['day_of_week'] == 'Saturday' or row['day_of_week'] == 'Sunday':\n",
    "        return \"nonextday\"\n",
    "    elif (row['date'].month == 1 and row['date'].day == 1) or (row['date'].month == 2 and row['date'].day >= 15 and row['date'].day <= 18) or \\\n",
    "    (row['date'].month == 3 and row['date'].day == 1) or (row['date'].month == 5 and row['date'].day >= 5 and row['date'].day <= 7) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 22) or (row['date'].month == 6 and row['date'].day == 6) or (row['date'].month == 6 and row['date'].day == 13) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 15) or (row['date'].month == 9 and row['date'].day >= 22 and row['date'].day <= 26) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 3) or (row['date'].month == 10 and row['date'].day == 9) or (row['date'].month == 12 and row['date'].day == 25):\n",
    "        return \"nonextday\"\n",
    "    elif row['day_of_week'] == 'Monday':\n",
    "        return 'nextday'\n",
    "    elif (row['date'].month == 1 and row['date'].day == 2) or (row['date'].month == 2 and row['date'].day >= 5 and row['date'].day <= 9) or \\\n",
    "    (row['date'].month == 2 and row['date'].day == 19) or (row['date'].month == 5 and row['date'].day == 8) or \\\n",
    "    (row['date'].month == 5 and row['date'].day == 23) or (row['date'].month == 6 and row['date'].day == 7) or (row['date'].month == 6 and row['date'].day == 14) or \\\n",
    "    (row['date'].month == 8 and row['date'].day == 16) or (row['date'].month == 9 and row['date'].day == 27) or (row['date'].month == 9 and row['date'].day >= 10 and row['date'].day <= 14) or \\\n",
    "    (row['date'].month == 10 and row['date'].day == 4) or (row['date'].month == 10 and row['date'].day == 10) or (row['date'].month == 12 and row['date'].day == 26):\n",
    "        return 'nextday'\n",
    "    else:\n",
    "        return 'nonextday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nextday'] = data.apply(set_nextday, axis=1)\n",
    "test['nextday'] = test.apply(set_nextday, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data 분배"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desti</th>\n",
       "      <th>quantity</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>nextday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5829</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>7455</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>10086</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5929</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>14913</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>winter</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  desti  quantity  month  day day_of_week  season    holiday  \\\n",
       "0 2017-12-01      0      5829     12    1      Friday  winter  noholiday   \n",
       "1 2017-12-01      1      7455     12    1      Friday  winter  noholiday   \n",
       "2 2017-12-01      2     10086     12    1      Friday  winter  noholiday   \n",
       "3 2017-12-01      3      5929     12    1      Friday  winter  noholiday   \n",
       "4 2017-12-01      4     14913     12    1      Friday  winter  noholiday   \n",
       "\n",
       "     nextday  \n",
       "0  nonextday  \n",
       "1  nonextday  \n",
       "2  nonextday  \n",
       "3  nonextday  \n",
       "4  nonextday  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data.drop([\"quantity\", \"date\"], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.drop([\"quantity\", \"date\", \"month\", \"day\"], axis=1) # 훈련 세트를 위해 레이블 삭제\n",
    "train_data_labels = data[\"quantity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cat = train_data[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "train_data_num = train_data.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.drop([\"date\"], axis=1)\n",
    "test_data_cat = test_data[['day_of_week', 'season', 'holiday', 'nextday']]\n",
    "test_data_num = test_data.drop(columns=['day_of_week', 'season', 'holiday', 'nextday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desti</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>nextday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>Monday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>Monday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>Monday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>Monday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>winter</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>12</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>holiday</td>\n",
       "      <td>nonextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>22</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>21</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>18</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>20</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>15</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>16</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>17</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>14</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>12</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>9</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>fall</td>\n",
       "      <td>noholiday</td>\n",
       "      <td>nextday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     desti day_of_week  season    holiday    nextday\n",
       "0       21      Sunday  winter    holiday  nonextday\n",
       "1       16      Sunday  winter    holiday  nonextday\n",
       "2       20      Sunday  winter    holiday  nonextday\n",
       "3        8      Sunday  winter    holiday  nonextday\n",
       "4       19      Sunday  winter    holiday  nonextday\n",
       "5        6      Sunday  winter    holiday  nonextday\n",
       "6        2      Sunday  winter    holiday  nonextday\n",
       "7       18      Sunday  winter    holiday  nonextday\n",
       "8       10      Sunday  winter    holiday  nonextday\n",
       "9       14      Sunday  winter    holiday  nonextday\n",
       "10      12      Sunday  winter    holiday  nonextday\n",
       "11       0      Sunday  winter    holiday  nonextday\n",
       "12      17      Sunday  winter    holiday  nonextday\n",
       "13      11      Sunday  winter    holiday  nonextday\n",
       "14       9      Sunday  winter    holiday  nonextday\n",
       "15      24      Sunday  winter    holiday  nonextday\n",
       "16       5      Sunday  winter    holiday  nonextday\n",
       "17       3      Sunday  winter    holiday  nonextday\n",
       "18       1      Sunday  winter    holiday  nonextday\n",
       "19      22      Sunday  winter    holiday  nonextday\n",
       "20      13      Sunday  winter    holiday  nonextday\n",
       "21       7      Sunday  winter    holiday  nonextday\n",
       "22       4      Sunday  winter    holiday  nonextday\n",
       "23      15      Sunday  winter    holiday  nonextday\n",
       "24      23      Sunday  winter    holiday  nonextday\n",
       "25      13      Monday  winter    holiday  nonextday\n",
       "26       8      Monday  winter    holiday  nonextday\n",
       "27      22      Monday  winter    holiday  nonextday\n",
       "28       7      Monday  winter    holiday  nonextday\n",
       "29       1      Monday  winter    holiday  nonextday\n",
       "..     ...         ...     ...        ...        ...\n",
       "395     11     Tuesday    fall    holiday  nonextday\n",
       "396     12     Tuesday    fall    holiday  nonextday\n",
       "397     14     Tuesday    fall    holiday  nonextday\n",
       "398      2     Tuesday    fall    holiday  nonextday\n",
       "399      8     Tuesday    fall    holiday  nonextday\n",
       "400      1   Wednesday    fall  noholiday    nextday\n",
       "401     24   Wednesday    fall  noholiday    nextday\n",
       "402      6   Wednesday    fall  noholiday    nextday\n",
       "403      2   Wednesday    fall  noholiday    nextday\n",
       "404      0   Wednesday    fall  noholiday    nextday\n",
       "405      4   Wednesday    fall  noholiday    nextday\n",
       "406     22   Wednesday    fall  noholiday    nextday\n",
       "407     21   Wednesday    fall  noholiday    nextday\n",
       "408      8   Wednesday    fall  noholiday    nextday\n",
       "409     11   Wednesday    fall  noholiday    nextday\n",
       "410     18   Wednesday    fall  noholiday    nextday\n",
       "411      3   Wednesday    fall  noholiday    nextday\n",
       "412     23   Wednesday    fall  noholiday    nextday\n",
       "413     20   Wednesday    fall  noholiday    nextday\n",
       "414     15   Wednesday    fall  noholiday    nextday\n",
       "415     19   Wednesday    fall  noholiday    nextday\n",
       "416      7   Wednesday    fall  noholiday    nextday\n",
       "417     16   Wednesday    fall  noholiday    nextday\n",
       "418     17   Wednesday    fall  noholiday    nextday\n",
       "419      5   Wednesday    fall  noholiday    nextday\n",
       "420     14   Wednesday    fall  noholiday    nextday\n",
       "421     12   Wednesday    fall  noholiday    nextday\n",
       "422     10   Wednesday    fall  noholiday    nextday\n",
       "423     13   Wednesday    fall  noholiday    nextday\n",
       "424      9   Wednesday    fall  noholiday    nextday\n",
       "\n",
       "[425 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding과 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4302e6d89aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mtrain_data_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;31m# validate names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "#         ('minmax_scaler', MinMaxScaler()),\n",
    "    ])\n",
    "\n",
    "\n",
    "num_attribs = list(train_data_num)\n",
    "cat_attribs = ['day_of_week', 'season', 'holiday', 'nextday']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "    \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "train_data_prepared = full_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = full_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.24835848, 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_prepared[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [7179.00886244 7220.37462591 7261.74038938 7303.10615285 7344.47191632]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플 몇 개를 사용해 전체 파이프라인을 적용\n",
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", lin_reg.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤포레스트 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = forest_reg.predict(train_data_prepared)\n",
    "forest_mse = mean_squared_error(train_data_labels, train_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [ 5910.1  7595.  10086.   6039.1 15518.7]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플 몇 개를 사용해 테스트하기\n",
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", forest_reg.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 최적화 하이퍼 파라미터 서치\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "min_samples_leaf = [1, 2, 4, 10, 50]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.3min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8010ae5bb89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n",
    "\n",
    "rf_random.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "union  = Pipeline([\n",
    "    ('k_means_5', KMeans(n_clusters=5)),\n",
    "    ('random_forest', RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.6min\n"
     ]
    }
   ],
   "source": [
    "union.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rf_random.best_estimator_.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.around(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  535.43648052,   280.71626768,   349.52555125,   142.05081955,\n",
       "         336.52802683,   187.38065134,   294.17350695,   342.16166062,\n",
       "         289.82781827,   330.06977091,   260.93116414,   193.76387147,\n",
       "         195.2783967 ,   279.88860994,   158.92999356,   272.54093377,\n",
       "         217.37738579,   327.49576912,   207.88006201,   760.70657952,\n",
       "         380.57643121,   279.58876059,  1616.12770076,   380.90268994,\n",
       "         569.58806592,   380.53629369,   198.10223155,   767.84004588,\n",
       "         300.56341258,   208.90951077,   365.30519134,   311.88287254,\n",
       "         257.01685027,   314.00256507,   587.7581095 ,   197.42331778,\n",
       "         316.42129   ,   349.22488849,   261.8796488 ,   308.15402545,\n",
       "         614.78730053,   287.56902693,   213.26212499,   361.01021814,\n",
       "         349.90483297,   237.71392801,   382.4868895 ,   323.46374392,\n",
       "        1672.30121122,   349.57698306, 12811.28574782, 21159.5395549 ,\n",
       "        9253.00749004,  5581.2782071 ,  8014.77066984,  9783.93395197,\n",
       "       14640.55182267, 11715.30674548, 14541.88465288,  9740.87525594,\n",
       "       10864.70984107, 14506.73229206, 21378.74554951, 13555.42946354,\n",
       "       10443.24218268,  8153.67697808,  8703.83141883,  8168.59344515,\n",
       "        6282.52510147, 10439.21006879,  8787.52238041, 11367.26829417,\n",
       "        9939.92536398, 10700.54127539, 11349.25816039,  5371.17225927,\n",
       "        4813.94881287,  6509.10293816,  3449.62972903, 13110.75067238,\n",
       "        8998.09140208,  6284.09569261,  6055.24493566,  3808.95725312,\n",
       "        5476.27138265,  5038.01216554,  4681.44323762,  6727.00302271,\n",
       "       13432.98569242,  7047.20349846,  6492.88781271,  5612.46821811,\n",
       "        5352.02488331,  8667.7461411 ,  6781.29078641,  8794.84840455,\n",
       "        8417.77590158,  6631.90858921,  8847.24584838,  7369.72482141,\n",
       "         343.17773142,   302.0349781 ,   424.27251554,   432.79437862,\n",
       "         338.63984796,   419.23567138,   422.54785645,   450.05508575,\n",
       "         516.53051986,   288.32915114,   484.26048651,   470.67328723,\n",
       "         485.76986983,   358.52869506,   454.41218541,   305.30803001,\n",
       "         495.60483319,  1638.57300309,   975.37384401,   375.81035458,\n",
       "         945.95632471,   344.01129514,   300.61589612,  1103.52417254,\n",
       "         491.32811746, 17786.49547337, 12710.54377914, 10043.18306709,\n",
       "       10306.71669343,  8446.88298073, 14432.17236327,  5677.39458255,\n",
       "        9091.08866417,  8420.49681135,  8808.35967978, 10897.49190645,\n",
       "       13337.13375627, 11421.79469542,  7178.54815608,  7774.32686301,\n",
       "       13746.95699392, 20115.29944607,  5400.03092587,  9966.46963873,\n",
       "       11297.40006365,  7501.58591166,  9196.73169487,  9835.65980825,\n",
       "       14139.34978326,  9726.34280962, 12757.56923867,  9200.55844211,\n",
       "        8478.58922604, 12960.01616961, 15939.33047103, 10656.38443939,\n",
       "       17853.68188823, 10394.99799842, 11050.40293102,  9136.10887256,\n",
       "        7174.70362635, 10867.86359464,  8162.59005024,  6075.27984655,\n",
       "        9468.92353075,  7295.62089787,  8946.89828598,  9103.90523958,\n",
       "        8881.68884   ,  4817.46348088,  8483.92911432,  9645.37486136,\n",
       "        6886.34157085,  6971.98624382,  5549.99789582,  2048.59710099,\n",
       "        1968.70837335,  1798.71367126,  1170.67554185,   731.6597339 ,\n",
       "        2049.2874253 ,  1742.7791495 ,  1416.0440037 ,  1370.417957  ,\n",
       "        1007.20026203,  3092.94111716,   653.48197534,  1047.14038673,\n",
       "         682.01234105,  1890.97689503,  1924.9194258 ,  1772.02898982,\n",
       "        1679.48299481,  1362.11984181,  1978.06806224,  1080.60188858,\n",
       "        1895.75780107,  1614.73332323,  1812.28519157,  1894.70907855,\n",
       "         593.56741997,  1170.29963477,   279.46220641,   335.04532806,\n",
       "         685.80183555,  1416.55936519,   281.40293998,   318.58987879,\n",
       "         265.02481586,  1204.26557751,   191.34679562,   302.39575547,\n",
       "         396.58612075,   317.01493339,   268.64932651,   238.92303256,\n",
       "        1365.24416822,   322.08486682,   241.66544295,   664.61860381,\n",
       "         261.23199754,   585.35813072,   209.3113845 ,   200.43483752,\n",
       "         910.56629738,   315.29282559,   302.91679851,   250.87039015,\n",
       "         262.60771916,  1171.97472045,   685.40866492,   279.79973635,\n",
       "         592.05947516,   663.30456791,  1392.04319149,   244.3933993 ,\n",
       "        1357.35743463,  1204.25255032,   394.39708341,   189.12690168,\n",
       "         332.97867254,   313.11988824,   208.80438029,   909.65452195,\n",
       "         258.8063827 ,   235.38349416,   578.93910116,   279.5946687 ,\n",
       "         323.98243558,   196.55308295,  8913.96442647,  6792.17566711,\n",
       "       11710.1757448 , 14414.67135698, 12746.30177473, 23875.31717899,\n",
       "       11146.55138561, 19419.3263335 , 12191.64458607, 14766.55924018,\n",
       "        9088.66214423, 18174.30939594, 11634.12133733, 10433.77437654,\n",
       "       10533.41408411, 15036.32089337, 12027.78967943, 14886.80660039,\n",
       "       13138.65490189,  7711.99585009,  9092.76470682, 11297.79534439,\n",
       "        9734.39114574, 17459.36119879, 12471.07259868,  4299.05369144,\n",
       "       11216.38816739,  8666.88029391, 10044.1943767 ,  7395.812141  ,\n",
       "       16081.63108453,  7630.25760952,  7972.75428782, 18120.78183829,\n",
       "        7201.98432447,  7516.03421197, 10913.9628203 ,  8613.47512047,\n",
       "       10966.36459017,  5871.33683858,  6301.99140944,  6080.17315104,\n",
       "        8220.14965014,  8015.60156494, 10079.68060362,  7427.31064765,\n",
       "        4694.40287587, 10732.97543161,  6898.54494394,  7160.20095253,\n",
       "         276.98905352,   250.06442001,   317.07325179,   407.71376707,\n",
       "         352.78487157,   455.75567333,   391.91434806,   363.68116705,\n",
       "         668.92009833,   316.89874796,   263.75426073,  2117.6241466 ,\n",
       "         314.37414209,   365.69928151,   309.89420694,   709.96909678,\n",
       "         230.42287205,   243.66097932,   351.91120997,   417.64520871,\n",
       "         451.57402581,   838.75664911,   442.67132853,   247.88987938,\n",
       "         399.53101587, 10200.98302312,  6963.96731344, 14517.78584079,\n",
       "       16446.58303817, 11362.95418566,  8662.86689051, 21746.76822177,\n",
       "       14276.68632431, 11887.18194081, 16669.95929738, 10847.96649396,\n",
       "       10123.76556789,  8732.20794633,  8586.06931446, 10651.8108833 ,\n",
       "       15752.43240559, 11603.50291583, 11151.66860185, 12043.67927427,\n",
       "        9780.89824546, 11799.47037671,  6472.58418106,  9702.83740096,\n",
       "       23210.25844362, 13727.85460537,  8767.60817423, 16662.87062396,\n",
       "       11516.90689499,  6637.75047557, 12330.88903532, 13284.85401836,\n",
       "       12136.40812765, 11707.56271207, 10612.696345  ,  7058.82316764,\n",
       "        8870.4450929 ,  8937.0780838 ,  9953.53451115, 11371.58286115,\n",
       "       14323.06889178, 23541.28188157, 16400.09698861, 16440.61174174,\n",
       "       10796.65747007,  9979.0276771 , 14852.84150675, 12723.81605716,\n",
       "       11880.88929208, 22250.32065052, 15086.23091777,   288.58390539,\n",
       "         726.81917126,   258.38631074,   413.51525073,   323.92365614,\n",
       "         854.63686365,   247.33329268,   326.16892453,   414.81585825,\n",
       "         371.13913806,   356.16884145,   450.52012322,   321.71841779,\n",
       "         462.39230265,   263.01160824,  1983.508818  ,   680.35918401,\n",
       "         398.26683713,   270.51178993,   460.17810098,   368.83669027,\n",
       "         356.07768556,   426.99556888,   370.82586815,   242.33651559,\n",
       "        9651.8669643 ,  8767.90758576, 10070.30976374, 15636.79458576,\n",
       "        8694.08209565, 21699.14011301, 23378.14263608, 16519.24009384,\n",
       "        6466.25967945, 10696.57188971, 11138.67380964,  9820.35816105,\n",
       "       16670.16729973, 12016.1302501 , 14270.20292417, 10819.99610224,\n",
       "       11562.40633754, 11331.3050853 ,  6953.34717658, 14507.59959079,\n",
       "       11835.41056917, 10137.62781834, 11923.90566817, 13754.00558192,\n",
       "        8586.12022003])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [  597.7   336.9   338.9   145.4   355.4   188.3   289.    357.1   337.9\n",
      "   337.4   246.1   201.7   172.    271.    177.6   295.6   238.6   358.6\n",
      "   211.6   771.6   401.8   313.3  1589.9   398.1   621.2   359.4   182.6\n",
      "   812.8   307.4   247.5   315.3   290.8   234.5   344.    546.3   233.1\n",
      "   355.7   312.5   156.    267.3   664.7   340.    236.9   298.1   445.8\n",
      "   218.6   324.9   368.7  1832.5   298.4 13247.6 20997.5  9298.2  5478.8\n",
      "  7822.7  9869.6 13939.3 11506.4 15194.5  9589.7 10246.3 14399.7 19987.3\n",
      " 13426.4 10164.1  7965.5  8045.4  8021.5  6112.7 10614.2  8888.7 11295.1\n",
      "  9611.5 10559.8 11318.8  4995.2  4985.5  6936.7  3332.3 12683.7  8814.9\n",
      "  5987.7  5921.4  3099.1  5290.8  5008.3  4432.3  5710.  13874.6  6599.8\n",
      "  6111.   6187.3  5836.   8668.1  7166.1  8873.2  8469.2  6864.7  8328.9\n",
      "  6979.2   214.2   269.9   457.4   408.2   304.4   386.1   461.4   448.2\n",
      "   605.1   239.8   429.3   450.6   466.6   452.1   330.9   302.4   607.4\n",
      "  2094.3   715.3   391.4   748.5   346.8   268.3   965.3   482.2 17436.8\n",
      " 12944.9  9979.8 10101.2  8468.6 13786.3  5875.2  9370.6  8191.4  8932.9\n",
      " 10776.7 13245.  10779.1  7173.2  7580.5 12978.3 19240.8  5261.8  9752.8\n",
      " 11207.5  7238.9  9156.3  9653.6 14090.1  9679.4 13001.4  9441.9  7961.1\n",
      " 13038.6 14993.8 11662.3 20523.4 10683.5 10441.9  9216.2  7561.1 11316.6\n",
      "  7896.9  6024.9 10160.6  7331.1  8042.1  9274.5  9227.1  5299.3  7349.4\n",
      " 10364.   6798.8  6463.1  4999.6  3487.8  2299.9  2037.2  1229.1   694.3\n",
      "  2352.4  2659.6  2462.5  1831.   2233.6  3199.    657.7  1921.1   722.4\n",
      "  2279.2  2156.6  1453.5  1310.9  1492.7  2053.8   950.8  1578.1  2156.1\n",
      "  1876.1  2118.2   215.7   571.4   258.1   384.8   474.5  1713.2   311.4\n",
      "   313.2   293.8   500.7   196.2   565.1   369.    336.1   301.2   245.4\n",
      "   653.    321.8   537.    278.8   280.5   212.9   184.6   195.3   311.8\n",
      "   301.1   559.9   303.6   285.6   545.4   475.1   306.8   216.6   277.\n",
      "  1720.7   534.7   592.6   467.3   359.4   191.8   371.8   325.6   166.\n",
      "   312.5   316.9   224.3   211.9   261.1   311.6   188.1  8506.8  6058.4\n",
      " 13731.8 15717.1 14026.2 25529.7 11636.9 19761.9 14074.6 16741.8 10325.8\n",
      " 20207.2 13991.8 10589.3 10174.8 14260.4 12310.9 13448.8 14437.2  7743.4\n",
      "  9957.6 12881.2 10098.8 19282.  13643.2  4248.9 11301.8  8761.7  9971.3\n",
      "  7600.3 15940.6  7616.7  7401.4 16429.1  7173.7  7956.1 10696.1  9046.2\n",
      " 11191.5  5690.3  6072.   6201.9  8486.1  8319.6 10334.   7743.5  4573.2\n",
      " 11047.7  6894.1  7108.9   212.1   212.9   307.1   361.5   288.5   439.8\n",
      "   333.3   337.2   555.2   278.4   163.4  2348.8   257.1   343.9   281.3\n",
      "   626.    173.2   205.8   293.6   344.6   465.3   796.6   407.4   230.\n",
      "   361.5  9781.9  6164.  12887.5 16508.3 11266.4  8529.1 23419.9 14825.6\n",
      " 12567.9 16101.5 10760.3  9669.   8659.1  8383.7 10819.6 15272.2 11632.7\n",
      " 11511.8 12100.1  9847.7 11055.3  6347.1 10066.9 23607.8 14587.3  8813.9\n",
      " 16529.5 11859.5  6612.4 13168.9 13901.6 11864.2 11771.4 10301.2  6746.\n",
      "  8903.2  9257.4 10230.1 11489.4 15113.  24271.5 16166.9 17774.3 10468.8\n",
      " 10312.3 15891.9 13304.4 12514.  23921.  15644.2   238.6   624.7   202.9\n",
      "   340.    280.5   844.2   197.1   270.5   353.9   356.1   311.1   404.8\n",
      "   310.1   456.5   223.1  2227.4   552.    303.3   171.2   399.5   332.4\n",
      "   296.2   329.3   386.6   171.7 10131.9  8858.7  9878.2 15247.6  8665.4\n",
      " 22523.6 23972.6 16350.4  6478.8 10937.  11933.  10302.2 16377.7 12068.7\n",
      " 14847.6 10301.1 11588.7 10885.6  6261.2 13923.1 11569.6  9771.1 12596.3\n",
      " 14538.   8518.5]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측:\", forest_reg.predict(test_data_prepared))\n",
    "result = forest_reg.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "ard = ARDRegression()\n",
    "ard.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", ard.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sgd.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR()\n",
    "clf.fit(train_data_prepared, train_data_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [6281.52328698 6287.43266756 6293.26016267 6298.97446499 6304.54378194]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", clf.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sgd.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor()\n",
    "# neigh.fit(train_data_prepared, train_data_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import GridSearchCV\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(neigh, param_grid, cv=10, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train_data_prepared, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [ 5829.  7455. 10086.  5929. 14913.]\n",
      "0     5829\n",
      "1     7455\n",
      "2    10086\n",
      "3     5929\n",
      "4    14913\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "some_data = temp_data.iloc[:5]\n",
    "some_labels = train_data_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"예측:\", grid.predict(some_data_prepared))\n",
    "print(some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2189650.640516039"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_int = result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  535,   280,   349,   142,   336,   187,   294,   342,   289,\n",
       "         330,   260,   193,   195,   279,   158,   272,   217,   327,\n",
       "         207,   760,   380,   279,  1616,   380,   569,   380,   198,\n",
       "         767,   300,   208,   365,   311,   257,   314,   587,   197,\n",
       "         316,   349,   261,   308,   614,   287,   213,   361,   349,\n",
       "         237,   382,   323,  1672,   349, 12811, 21159,  9253,  5581,\n",
       "        8014,  9783, 14640, 11715, 14541,  9740, 10864, 14506, 21378,\n",
       "       13555, 10443,  8153,  8703,  8168,  6282, 10439,  8787, 11367,\n",
       "        9939, 10700, 11349,  5371,  4813,  6509,  3449, 13110,  8998,\n",
       "        6284,  6055,  3808,  5476,  5038,  4681,  6727, 13432,  7047,\n",
       "        6492,  5612,  5352,  8667,  6781,  8794,  8417,  6631,  8847,\n",
       "        7369,   343,   302,   424,   432,   338,   419,   422,   450,\n",
       "         516,   288,   484,   470,   485,   358,   454,   305,   495,\n",
       "        1638,   975,   375,   945,   344,   300,  1103,   491, 17786,\n",
       "       12710, 10043, 10306,  8446, 14432,  5677,  9091,  8420,  8808,\n",
       "       10897, 13337, 11421,  7178,  7774, 13746, 20115,  5400,  9966,\n",
       "       11297,  7501,  9196,  9835, 14139,  9726, 12757,  9200,  8478,\n",
       "       12960, 15939, 10656, 17853, 10394, 11050,  9136,  7174, 10867,\n",
       "        8162,  6075,  9468,  7295,  8946,  9103,  8881,  4817,  8483,\n",
       "        9645,  6886,  6971,  5549,  2048,  1968,  1798,  1170,   731,\n",
       "        2049,  1742,  1416,  1370,  1007,  3092,   653,  1047,   682,\n",
       "        1890,  1924,  1772,  1679,  1362,  1978,  1080,  1895,  1614,\n",
       "        1812,  1894,   593,  1170,   279,   335,   685,  1416,   281,\n",
       "         318,   265,  1204,   191,   302,   396,   317,   268,   238,\n",
       "        1365,   322,   241,   664,   261,   585,   209,   200,   910,\n",
       "         315,   302,   250,   262,  1171,   685,   279,   592,   663,\n",
       "        1392,   244,  1357,  1204,   394,   189,   332,   313,   208,\n",
       "         909,   258,   235,   578,   279,   323,   196,  8913,  6792,\n",
       "       11710, 14414, 12746, 23875, 11146, 19419, 12191, 14766,  9088,\n",
       "       18174, 11634, 10433, 10533, 15036, 12027, 14886, 13138,  7711,\n",
       "        9092, 11297,  9734, 17459, 12471,  4299, 11216,  8666, 10044,\n",
       "        7395, 16081,  7630,  7972, 18120,  7201,  7516, 10913,  8613,\n",
       "       10966,  5871,  6301,  6080,  8220,  8015, 10079,  7427,  4694,\n",
       "       10732,  6898,  7160,   276,   250,   317,   407,   352,   455,\n",
       "         391,   363,   668,   316,   263,  2117,   314,   365,   309,\n",
       "         709,   230,   243,   351,   417,   451,   838,   442,   247,\n",
       "         399, 10200,  6963, 14517, 16446, 11362,  8662, 21746, 14276,\n",
       "       11887, 16669, 10847, 10123,  8732,  8586, 10651, 15752, 11603,\n",
       "       11151, 12043,  9780, 11799,  6472,  9702, 23210, 13727,  8767,\n",
       "       16662, 11516,  6637, 12330, 13284, 12136, 11707, 10612,  7058,\n",
       "        8870,  8937,  9953, 11371, 14323, 23541, 16400, 16440, 10796,\n",
       "        9979, 14852, 12723, 11880, 22250, 15086,   288,   726,   258,\n",
       "         413,   323,   854,   247,   326,   414,   371,   356,   450,\n",
       "         321,   462,   263,  1983,   680,   398,   270,   460,   368,\n",
       "         356,   426,   370,   242,  9651,  8767, 10070, 15636,  8694,\n",
       "       21699, 23378, 16519,  6466, 10696, 11138,  9820, 16670, 12016,\n",
       "       14270, 10819, 11562, 11331,  6953, 14507, 11835, 10137, 11923,\n",
       "       13754,  8586])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/submit_example.csv', encoding='utf-8', names=[\"date\", \"desti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd = pd.DataFrame(result_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv = pd.concat([submit, result_pd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv.to_csv('submit.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For deep learning model \n",
    "import keras\n",
    "from keras.layers import Dense, Input, concatenate, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5829,  7455, 10086, ..., 16106, 11191,  5884], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_prepared\n",
    "Y = train_data_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6883 samples, validate on 1721 samples\n",
      "Epoch 1/100\n",
      "6883/6883 [==============================] - 5s 782us/step - loss: 24019806.9369 - acc: 1.4529e-04 - val_loss: 15990906.0802 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6883/6883 [==============================] - 5s 764us/step - loss: 6298805.1723 - acc: 7.2643e-04 - val_loss: 15765093.7501 - val_acc: 5.8106e-04\n",
      "Epoch 3/100\n",
      "6883/6883 [==============================] - 5s 699us/step - loss: 6251347.2159 - acc: 4.3586e-04 - val_loss: 15600993.8791 - val_acc: 0.0012\n",
      "Epoch 4/100\n",
      "6883/6883 [==============================] - 6s 801us/step - loss: 6195917.1405 - acc: 5.8114e-04 - val_loss: 15758208.9367 - val_acc: 0.0017\n",
      "Epoch 5/100\n",
      "6883/6883 [==============================] - 6s 808us/step - loss: 6160372.7108 - acc: 8.7171e-04 - val_loss: 16865049.9187 - val_acc: 5.8106e-04\n",
      "Epoch 6/100\n",
      "6883/6883 [==============================] - 6s 821us/step - loss: 6040295.2510 - acc: 7.2643e-04 - val_loss: 15573848.6357 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6883/6883 [==============================] - 5s 727us/step - loss: 5943928.5960 - acc: 0.0010 - val_loss: 15167778.4567 - val_acc: 5.8106e-04\n",
      "Epoch 8/100\n",
      "6883/6883 [==============================] - 5s 670us/step - loss: 5939147.7920 - acc: 5.8114e-04 - val_loss: 16682843.9268 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5945700.5487 - acc: 2.9057e-04 - val_loss: 14636323.5921 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5905947.5020 - acc: 1.4529e-04 - val_loss: 13896459.8466 - val_acc: 5.8106e-04\n",
      "Epoch 11/100\n",
      "6883/6883 [==============================] - 5s 678us/step - loss: 5847400.2463 - acc: 0.0000e+00 - val_loss: 14068904.1290 - val_acc: 5.8106e-04\n",
      "Epoch 12/100\n",
      "6883/6883 [==============================] - 6s 841us/step - loss: 5811174.6779 - acc: 7.2643e-04 - val_loss: 15244086.2324 - val_acc: 5.8106e-04\n",
      "Epoch 13/100\n",
      "6883/6883 [==============================] - 5s 738us/step - loss: 5795962.3748 - acc: 4.3586e-04 - val_loss: 14654568.7542 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6883/6883 [==============================] - 5s 727us/step - loss: 5760606.8887 - acc: 2.9057e-04 - val_loss: 13850974.5131 - val_acc: 5.8106e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/100\n",
      "6883/6883 [==============================] - 5s 791us/step - loss: 5621148.1685 - acc: 5.8114e-04 - val_loss: 14369183.4492 - val_acc: 5.8106e-04\n",
      "Epoch 16/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 5579183.3397 - acc: 0.0012 - val_loss: 15293432.8449 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 5667122.9441 - acc: 0.0013 - val_loss: 14227727.9814 - val_acc: 5.8106e-04\n",
      "Epoch 18/100\n",
      "6883/6883 [==============================] - 6s 873us/step - loss: 5685772.6449 - acc: 0.0012 - val_loss: 13626366.6630 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "6883/6883 [==============================] - 5s 732us/step - loss: 5571248.0236 - acc: 8.7171e-04 - val_loss: 13345354.6496 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "6883/6883 [==============================] - 5s 654us/step - loss: 5562476.2492 - acc: 0.0012 - val_loss: 13829882.5450 - val_acc: 5.8106e-04\n",
      "Epoch 21/100\n",
      "6883/6883 [==============================] - 5s 662us/step - loss: 5579529.8404 - acc: 4.3586e-04 - val_loss: 13869256.0209 - val_acc: 0.0012\n",
      "Epoch 22/100\n",
      "6883/6883 [==============================] - 6s 883us/step - loss: 5568244.7356 - acc: 7.2643e-04 - val_loss: 13276337.5811 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5606410.7729 - acc: 4.3586e-04 - val_loss: 13716067.3225 - val_acc: 0.0012\n",
      "Epoch 24/100\n",
      "6883/6883 [==============================] - 5s 720us/step - loss: 5557764.0892 - acc: 7.2643e-04 - val_loss: 14189512.7862 - val_acc: 0.0023\n",
      "Epoch 25/100\n",
      "6883/6883 [==============================] - 5s 777us/step - loss: 5538916.5460 - acc: 8.7171e-04 - val_loss: 14962774.7403 - val_acc: 5.8106e-04\n",
      "Epoch 26/100\n",
      "6883/6883 [==============================] - 4s 644us/step - loss: 5495006.7144 - acc: 0.0016 - val_loss: 14522017.6595 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "6883/6883 [==============================] - 5s 778us/step - loss: 5515965.8765 - acc: 0.0012 - val_loss: 13828898.3295 - val_acc: 0.0012\n",
      "Epoch 28/100\n",
      "6883/6883 [==============================] - 6s 887us/step - loss: 5404347.8080 - acc: 5.8114e-04 - val_loss: 12903234.0151 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "6883/6883 [==============================] - 6s 850us/step - loss: 5405666.4975 - acc: 7.2643e-04 - val_loss: 13211277.6212 - val_acc: 0.0012\n",
      "Epoch 30/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 5390765.5283 - acc: 5.8114e-04 - val_loss: 13982347.6310 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "6883/6883 [==============================] - 5s 783us/step - loss: 5389808.3772 - acc: 5.8114e-04 - val_loss: 13446817.1040 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "6883/6883 [==============================] - 5s 792us/step - loss: 5347761.2576 - acc: 0.0012 - val_loss: 14613208.6851 - val_acc: 5.8106e-04\n",
      "Epoch 33/100\n",
      "6883/6883 [==============================] - 5s 733us/step - loss: 5368655.0023 - acc: 7.2643e-04 - val_loss: 14565507.5752 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "6883/6883 [==============================] - 5s 714us/step - loss: 5386407.9248 - acc: 5.8114e-04 - val_loss: 14366548.1697 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/100\n",
      "6883/6883 [==============================] - 6s 935us/step - loss: 5292213.0584 - acc: 4.3586e-04 - val_loss: 13773750.6351 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "6883/6883 [==============================] - 5s 715us/step - loss: 5309293.5115 - acc: 8.7171e-04 - val_loss: 13800923.0105 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "6883/6883 [==============================] - 5s 739us/step - loss: 5196658.7908 - acc: 7.2643e-04 - val_loss: 13735348.3283 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "6883/6883 [==============================] - 5s 680us/step - loss: 5248661.8132 - acc: 0.0013 - val_loss: 14097858.2795 - val_acc: 5.8106e-04\n",
      "Epoch 39/100\n",
      "6883/6883 [==============================] - 5s 733us/step - loss: 5170393.5544 - acc: 8.7171e-04 - val_loss: 13527830.5044 - val_acc: 0.0012\n",
      "Epoch 40/100\n",
      "6883/6883 [==============================] - 5s 670us/step - loss: 5155401.6519 - acc: 0.0015 - val_loss: 13404002.1888 - val_acc: 0.0012\n",
      "Epoch 41/100\n",
      "6883/6883 [==============================] - 5s 672us/step - loss: 5201360.4335 - acc: 8.7171e-04 - val_loss: 13209872.4248 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "6883/6883 [==============================] - 5s 713us/step - loss: 5139656.8556 - acc: 5.8114e-04 - val_loss: 13343570.3382 - val_acc: 0.0012\n",
      "Epoch 43/100\n",
      "6883/6883 [==============================] - 5s 679us/step - loss: 5120288.5767 - acc: 8.7171e-04 - val_loss: 13369424.9861 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "6883/6883 [==============================] - 5s 669us/step - loss: 5165525.4498 - acc: 8.7171e-04 - val_loss: 13652060.5445 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 5171312.4841 - acc: 2.9057e-04 - val_loss: 13565098.1220 - val_acc: 5.8106e-04\n",
      "Epoch 46/100\n",
      "6883/6883 [==============================] - 5s 672us/step - loss: 5121748.8350 - acc: 7.2643e-04 - val_loss: 13712346.4248 - val_acc: 5.8106e-04\n",
      "Epoch 47/100\n",
      "6883/6883 [==============================] - 5s 664us/step - loss: 5122999.8482 - acc: 2.9057e-04 - val_loss: 13248028.6467 - val_acc: 0.0012\n",
      "Epoch 48/100\n",
      "6883/6883 [==============================] - 5s 671us/step - loss: 5129981.3772 - acc: 2.9057e-04 - val_loss: 13498506.2719 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 5128698.7664 - acc: 5.8114e-04 - val_loss: 13374864.5863 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 5166929.0145 - acc: 7.2643e-04 - val_loss: 13547611.3661 - val_acc: 0.0012\n",
      "Epoch 51/100\n",
      "6883/6883 [==============================] - 5s 677us/step - loss: 5081680.0230 - acc: 5.8114e-04 - val_loss: 13868442.3730 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "6883/6883 [==============================] - 5s 677us/step - loss: 5093951.7938 - acc: 2.9057e-04 - val_loss: 13059316.0378 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "6883/6883 [==============================] - 5s 699us/step - loss: 5064138.1944 - acc: 0.0013 - val_loss: 13501176.0674 - val_acc: 5.8106e-04\n",
      "Epoch 54/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 5180120.4961 - acc: 4.3586e-04 - val_loss: 13698856.4399 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 55/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5058769.5119 - acc: 0.0016 - val_loss: 13444566.1302 - val_acc: 5.8106e-04\n",
      "Epoch 56/100\n",
      "6883/6883 [==============================] - 5s 691us/step - loss: 5101156.0253 - acc: 5.8114e-04 - val_loss: 13783711.8414 - val_acc: 0.0012\n",
      "Epoch 57/100\n",
      "6883/6883 [==============================] - 5s 721us/step - loss: 5059946.9300 - acc: 4.3586e-04 - val_loss: 13413629.4021 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "6883/6883 [==============================] - 5s 665us/step - loss: 5051410.2387 - acc: 8.7171e-04 - val_loss: 13394703.1075 - val_acc: 0.0012\n",
      "Epoch 59/100\n",
      "6883/6883 [==============================] - 5s 687us/step - loss: 5072371.0222 - acc: 8.7171e-04 - val_loss: 13359180.6920 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "6883/6883 [==============================] - 5s 678us/step - loss: 5018443.3853 - acc: 7.2643e-04 - val_loss: 13524953.6967 - val_acc: 5.8106e-04\n",
      "Epoch 61/100\n",
      "6883/6883 [==============================] - 5s 666us/step - loss: 4969843.6682 - acc: 5.8114e-04 - val_loss: 13501740.4550 - val_acc: 5.8106e-04\n",
      "Epoch 62/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 4983171.3291 - acc: 8.7171e-04 - val_loss: 13383423.1203 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "6883/6883 [==============================] - 5s 659us/step - loss: 4977258.2212 - acc: 8.7171e-04 - val_loss: 13139032.4730 - val_acc: 5.8106e-04\n",
      "Epoch 64/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 4982331.3968 - acc: 5.8114e-04 - val_loss: 13504124.0209 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 5034110.7996 - acc: 5.8114e-04 - val_loss: 13426658.7147 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 5037275.3762 - acc: 8.7171e-04 - val_loss: 13553244.6630 - val_acc: 0.0012\n",
      "Epoch 67/100\n",
      "6883/6883 [==============================] - 4s 652us/step - loss: 5016273.1809 - acc: 7.2643e-04 - val_loss: 13429034.4788 - val_acc: 5.8106e-04\n",
      "Epoch 68/100\n",
      "6883/6883 [==============================] - 5s 655us/step - loss: 5030558.1437 - acc: 4.3586e-04 - val_loss: 13561632.5462 - val_acc: 0.0012\n",
      "Epoch 69/100\n",
      "6883/6883 [==============================] - 4s 648us/step - loss: 5022771.6062 - acc: 7.2643e-04 - val_loss: 13460405.6758 - val_acc: 0.0012\n",
      "Epoch 70/100\n",
      "6883/6883 [==============================] - 5s 667us/step - loss: 4997948.0024 - acc: 8.7171e-04 - val_loss: 13387042.8239 - val_acc: 5.8106e-04\n",
      "Epoch 71/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 5002514.0522 - acc: 8.7171e-04 - val_loss: 13437422.7362 - val_acc: 0.0012\n",
      "Epoch 72/100\n",
      "6883/6883 [==============================] - 5s 654us/step - loss: 5027051.8759 - acc: 0.0017 - val_loss: 13413638.2243 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "6883/6883 [==============================] - 5s 660us/step - loss: 4999133.6399 - acc: 1.4529e-04 - val_loss: 13386886.3213 - val_acc: 5.8106e-04\n",
      "Epoch 74/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 5034712.0774 - acc: 0.0013 - val_loss: 13378870.3051 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 75/100\n",
      "6883/6883 [==============================] - 5s 676us/step - loss: 4974733.3351 - acc: 8.7171e-04 - val_loss: 13446774.5625 - val_acc: 5.8106e-04\n",
      "Epoch 76/100\n",
      "6883/6883 [==============================] - 5s 674us/step - loss: 4955611.3300 - acc: 4.3586e-04 - val_loss: 13398580.3719 - val_acc: 0.0012\n",
      "Epoch 77/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5022593.7733 - acc: 2.9057e-04 - val_loss: 13459559.4718 - val_acc: 0.0012\n",
      "Epoch 78/100\n",
      "6883/6883 [==============================] - 5s 676us/step - loss: 4983919.4796 - acc: 5.8114e-04 - val_loss: 13439210.5270 - val_acc: 0.0012\n",
      "Epoch 79/100\n",
      "6883/6883 [==============================] - 5s 664us/step - loss: 4910187.8425 - acc: 7.2643e-04 - val_loss: 13399135.5212 - val_acc: 5.8106e-04\n",
      "Epoch 80/100\n",
      "6883/6883 [==============================] - 4s 651us/step - loss: 4974858.7426 - acc: 2.9057e-04 - val_loss: 13449256.5206 - val_acc: 5.8106e-04\n",
      "Epoch 81/100\n",
      "6883/6883 [==============================] - 5s 662us/step - loss: 4961609.8817 - acc: 7.2643e-04 - val_loss: 13467521.3963 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "6883/6883 [==============================] - 4s 653us/step - loss: 4975563.6873 - acc: 8.7171e-04 - val_loss: 13409012.1859 - val_acc: 0.0012\n",
      "Epoch 83/100\n",
      "6883/6883 [==============================] - 5s 695us/step - loss: 4951099.0151 - acc: 0.0012 - val_loss: 13439802.8919 - val_acc: 5.8106e-04\n",
      "Epoch 84/100\n",
      "6883/6883 [==============================] - 6s 882us/step - loss: 4941026.2481 - acc: 7.2643e-04 - val_loss: 13421417.5805 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 85/100\n",
      "6883/6883 [==============================] - 6s 914us/step - loss: 4997101.6114 - acc: 7.2643e-04 - val_loss: 13431274.3498 - val_acc: 0.0012\n",
      "Epoch 86/100\n",
      "6883/6883 [==============================] - 5s 748us/step - loss: 5041673.6389 - acc: 5.8114e-04 - val_loss: 13416292.0261 - val_acc: 5.8106e-04\n",
      "Epoch 87/100\n",
      "6883/6883 [==============================] - 7s 973us/step - loss: 4956891.5886 - acc: 4.3586e-04 - val_loss: 13418018.6089 - val_acc: 5.8106e-04\n",
      "Epoch 88/100\n",
      "6883/6883 [==============================] - 6s 913us/step - loss: 4979234.0434 - acc: 4.3586e-04 - val_loss: 13414014.1726 - val_acc: 5.8106e-04\n",
      "Epoch 89/100\n",
      "6883/6883 [==============================] - 7s 1ms/step - loss: 4958917.1951 - acc: 0.0010 - val_loss: 13427352.2202 - val_acc: 5.8106e-04\n",
      "Epoch 90/100\n",
      "6883/6883 [==============================] - 6s 822us/step - loss: 4985241.5978 - acc: 4.3586e-04 - val_loss: 13424677.2661 - val_acc: 0.0012\n",
      "Epoch 91/100\n",
      "6883/6883 [==============================] - 5s 682us/step - loss: 5010232.6526 - acc: 0.0013 - val_loss: 13402227.4126 - val_acc: 5.8106e-04\n",
      "Epoch 92/100\n",
      "6883/6883 [==============================] - 5s 690us/step - loss: 5009976.4831 - acc: 0.0010 - val_loss: 13409398.7013 - val_acc: 0.0017\n",
      "Epoch 93/100\n",
      "6883/6883 [==============================] - 5s 714us/step - loss: 5007828.2416 - acc: 0.0015 - val_loss: 13387353.9268 - val_acc: 0.0012\n",
      "Epoch 94/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 4991460.9127 - acc: 5.8114e-04 - val_loss: 13386499.4033 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 95/100\n",
      "6883/6883 [==============================] - 5s 661us/step - loss: 5018218.9831 - acc: 2.9057e-04 - val_loss: 13392491.0732 - val_acc: 0.0012\n",
      "Epoch 96/100\n",
      "6883/6883 [==============================] - 5s 681us/step - loss: 4983028.4490 - acc: 7.2643e-04 - val_loss: 13393797.5828 - val_acc: 0.0012\n",
      "Epoch 97/100\n",
      "6883/6883 [==============================] - 5s 763us/step - loss: 4959255.4094 - acc: 4.3586e-04 - val_loss: 13396459.8135 - val_acc: 0.0012\n",
      "Epoch 98/100\n",
      "6883/6883 [==============================] - 5s 755us/step - loss: 4989062.6642 - acc: 7.2643e-04 - val_loss: 13391451.2719 - val_acc: 0.0012\n",
      "Epoch 99/100\n",
      "6883/6883 [==============================] - 5s 658us/step - loss: 5006413.5400 - acc: 0.0012 - val_loss: 13392577.1354 - val_acc: 0.0012\n",
      "Epoch 100/100\n",
      "6883/6883 [==============================] - 5s 686us/step - loss: 4927212.1027 - acc: 8.7171e-04 - val_loss: 13403480.7037 - val_acc: 0.0012\n"
     ]
    }
   ],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense((1024), activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense((512), activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense((256), activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(1, name='num_output')(x)\n",
    "\n",
    "model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=10, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "#     EarlyStopping('val_loss', patience=15)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "]\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, batch_size=64, callbacks=callbacks, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
